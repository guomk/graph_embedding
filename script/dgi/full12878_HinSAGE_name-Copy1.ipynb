{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5inT3APPel92"
   },
   "source": [
    "# Node representation learning with Deep Graph Infomax and HinSAGE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DsTXmAsKel93"
   },
   "source": [
    "This demo demonstrates how to perform unsupervised training of a GCN, GAT, APPNP, or GraphSAGE model using the Deep Graph Infomax algorithm (https://arxiv.org/pdf/1809.10341.pdf) on the GM12878_sample dataset. \n",
    "\n",
    "As with all StellarGraph workflows: first we load the dataset, next we create our data generators, and then we train our model. We then take the embeddings created through unsupervised training and predict the node classes using logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2020-06-15T01:45:53.871786Z",
     "iopub.status.busy": "2020-06-15T01:45:53.871786Z",
     "iopub.status.idle": "2020-06-15T01:45:58.590297Z",
     "shell.execute_reply": "2020-06-15T01:45:58.590297Z",
     "shell.execute_reply.started": "2020-06-15T01:45:53.871786Z"
    },
    "id": "nA4FZSrKel97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "from stellargraph.mapper import (\n",
    "    CorruptedGenerator,\n",
    "    FullBatchNodeGenerator,\n",
    "    GraphSAGENodeGenerator,\n",
    "    HinSAGENodeGenerator,\n",
    ")\n",
    "from stellargraph import StellarDiGraph\n",
    "from stellargraph.layer import GCN, DeepGraphInfomax, GraphSAGE, GAT, APPNP, HinSAGE\n",
    "\n",
    "from stellargraph import datasets\n",
    "from stellargraph.utils import plot_history\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.manifold import TSNE\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "if tf.test.gpu_device_name():\n",
    "  print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xKLFlEiWel99",
    "tags": [
     "DataLoadingLinks"
    ]
   },
   "source": [
    "(See [the \"Loading from Pandas\" demo](../basics/loading-pandas.ipynb) for details on how data can be loaded.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load graph and node features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-15T01:45:58.591298Z",
     "iopub.status.busy": "2020-06-15T01:45:58.591298Z",
     "iopub.status.idle": "2020-06-15T01:46:10.278360Z",
     "shell.execute_reply": "2020-06-15T01:46:10.278360Z",
     "shell.execute_reply.started": "2020-06-15T01:45:58.591298Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = Path(\"../../data/\")\n",
    "FEATURE_FOLDER = Path('../../data/features/')\n",
    "FILE_NAME = 'joint_renamed.csv'\n",
    "FEATURE_FILE = 'joint_renamed_onehot_names.csv'\n",
    "SEP = ','\n",
    "\n",
    "df = pd.read_csv(DATA_FOLDER / FILE_NAME, sep=SEP)[['cell_type', 'source', 'target', 'weight', 'type']]\n",
    "\n",
    "feature_df = pd.read_csv(FEATURE_FOLDER / FEATURE_FILE, index_col=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-15T01:46:10.279707Z",
     "iopub.status.busy": "2020-06-15T01:46:10.279707Z",
     "iopub.status.idle": "2020-06-15T01:46:11.071908Z",
     "shell.execute_reply": "2020-06-15T01:46:11.071908Z",
     "shell.execute_reply.started": "2020-06-15T01:46:10.279707Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StellarDiGraph: Directed multigraph\n",
      " Nodes: 8829, Edges: 46680\n",
      "\n",
      " Node types:\n",
      "  default: [8829]\n",
      "    Features: float32 vector, length 8829\n",
      "    Edge types: default-0->default, default-1->default\n",
      "\n",
      " Edge types:\n",
      "    default-0->default: [42076]\n",
      "        Weights: all 1 (default)\n",
      "        Features: none\n",
      "    default-1->default: [4604]\n",
      "        Weights: all 1 (default)\n",
      "        Features: none\n"
     ]
    }
   ],
   "source": [
    "df['edge_type'] = df['type'].map(lambda x: 1 if x == 'TSS' else 0)\n",
    "\n",
    "\n",
    "G = StellarDiGraph(edges=df[['source', 'target', 'edge_type']], edge_type_column='edge_type', nodes=feature_df)\n",
    "print(G.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hnm1j3a5el-A"
   },
   "source": [
    "## Data Generators\n",
    "\n",
    "Now we create the data generators using `CorruptedGenerator`. `CorruptedGenerator` returns shuffled node features along with the regular node features and we train our model to discriminate between the two. \n",
    "\n",
    "Note that:\n",
    "\n",
    "- We typically pass all nodes to `corrupted_generator.flow` because this is an unsupervised task\n",
    "- We don't pass `targets` to `corrupted_generator.flow` because these are binary labels (true nodes, false nodes) that are created by `CorruptedGenerator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2020-06-15T01:46:11.073909Z",
     "iopub.status.busy": "2020-06-15T01:46:11.072909Z",
     "iopub.status.idle": "2020-06-15T01:46:11.102910Z",
     "shell.execute_reply": "2020-06-15T01:46:11.102910Z",
     "shell.execute_reply.started": "2020-06-15T01:46:11.072909Z"
    },
    "id": "oGwDi_zeel-A",
    "outputId": "866833d4-f7ed-4dda-c58c-353f19e921ac"
   },
   "outputs": [],
   "source": [
    "# HinSAGE model \n",
    "hinsage_generator = HinSAGENodeGenerator(\n",
    "    G, batch_size=50, num_samples=[10, 10]\n",
    ")\n",
    "\n",
    "hinsage_model = HinSAGE(\n",
    "    layer_sizes=[64, 64], activations=[\"linear\", \"relu\"], generator=hinsage_generator\n",
    ")\n",
    "# hinsage_acc = run_deep_graph_infomax(hinsage_model, hinsage_generator, epochs=epochs)\n",
    "\n",
    "# print(f\"Test classification accuracy: {hinsage_acc}\")\n",
    "\n",
    "corrupted_generator = CorruptedGenerator(hinsage_generator)\n",
    "gen = corrupted_generator.flow(G.nodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JiiPI3qMel-C"
   },
   "source": [
    "## Model Creation and Training\n",
    "\n",
    "We create and train our `DeepGraphInfomax` model. Note that the loss used here must always be `tf.nn.sigmoid_cross_entropy_with_logits`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2020-06-15T01:46:11.103910Z",
     "iopub.status.busy": "2020-06-15T01:46:11.103910Z",
     "iopub.status.idle": "2020-06-15T01:46:12.054909Z",
     "shell.execute_reply": "2020-06-15T01:46:12.054909Z",
     "shell.execute_reply.started": "2020-06-15T01:46:11.103910Z"
    },
    "id": "l82u77L5el-C"
   },
   "outputs": [],
   "source": [
    "infomax = DeepGraphInfomax(hinsage_model, corrupted_generator)\n",
    "x_in, x_out = infomax.in_out_tensors()\n",
    "\n",
    "model = Model(inputs=x_in, outputs=x_out)\n",
    "model.compile(loss=tf.nn.sigmoid_cross_entropy_with_logits, \n",
    "              optimizer=Adam(lr=1e-3),\n",
    "#               metrics=['loss']\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2020-06-15T01:46:12.055909Z",
     "iopub.status.busy": "2020-06-15T01:46:12.055909Z",
     "iopub.status.idle": "2020-06-15T01:46:12.069910Z",
     "shell.execute_reply": "2020-06-15T01:46:12.069910Z",
     "shell.execute_reply.started": "2020-06-15T01:46:12.055909Z"
    },
    "id": "2wCQIugxel-E",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-15T01:46:12.070913Z",
     "iopub.status.busy": "2020-06-15T01:46:12.070913Z",
     "iopub.status.idle": "2020-06-15T01:46:12.085910Z",
     "shell.execute_reply": "2020-06-15T01:46:12.085910Z",
     "shell.execute_reply.started": "2020-06-15T01:46:12.070913Z"
    }
   },
   "outputs": [],
   "source": [
    "# # checkpoint (Not working here)\n",
    "# filepath=\"./checkpoints/weights-improvement-{epoch:02d}-{loss:.2f}.hdf5\"\n",
    "# cp = tf.keras.callbacks.ModelCheckpoint(str(filepath), \n",
    "#                              monitor='loss', \n",
    "#                              verbose=0, \n",
    "#                              save_best_only=True, \n",
    "#                              save_weights_only=True,\n",
    "#                              mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2020-06-15T01:46:12.087912Z",
     "iopub.status.busy": "2020-06-15T01:46:12.087912Z",
     "iopub.status.idle": "2020-06-15T07:05:58.324052Z",
     "shell.execute_reply": "2020-06-15T07:05:58.324052Z",
     "shell.execute_reply.started": "2020-06-15T01:46:12.087912Z"
    },
    "id": "uUnlywYael-G",
    "outputId": "0fdf7b8c-dbca-4575-e9f0-16aa79931772"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 177 steps\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 194s 1s/step - loss: 0.0975\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 197s 1s/step - loss: 0.0016\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 194s 1s/step - loss: 5.7751e-04\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 196s 1s/step - loss: 3.1084e-04\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 195s 1s/step - loss: 1.8799e-04\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 194s 1s/step - loss: 1.5307e-04\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 194s 1s/step - loss: 9.7489e-05\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 195s 1s/step - loss: 8.3846e-05\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 194s 1s/step - loss: 7.4434e-05\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 193s 1s/step - loss: 5.5026e-05\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 194s 1s/step - loss: 5.1825e-05\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 195s 1s/step - loss: 3.9434e-05\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 194s 1s/step - loss: 3.1749e-05\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 194s 1s/step - loss: 8.5814e-04\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 193s 1s/step - loss: 0.0011\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 193s 1s/step - loss: 2.6236e-04\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 195s 1s/step - loss: 5.0639e-05\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 197s 1s/step - loss: 7.1038e-05\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 193s 1s/step - loss: 2.3634e-05\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 195s 1s/step - loss: 2.8072e-05\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 191s 1s/step - loss: 1.0341e-04\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 192s 1s/step - loss: 8.2222e-05\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 191s 1s/step - loss: 0.0073\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 190s 1s/step - loss: 5.6823e-04\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 193s 1s/step - loss: 1.0357e-04\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 190s 1s/step - loss: 3.1389e-05\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 190s 1s/step - loss: 1.8491e-05\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 190s 1s/step - loss: 1.4908e-05\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 190s 1s/step - loss: 9.7578e-06\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 190s 1s/step - loss: 1.1869e-05\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 189s 1s/step - loss: 1.1372e-05\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 190s 1s/step - loss: 8.9034e-06\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 189s 1s/step - loss: 8.7291e-06\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 190s 1s/step - loss: 7.4937e-06\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 189s 1s/step - loss: 7.5470e-06\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 195s 1s/step - loss: 3.2372e-05\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 197s 1s/step - loss: 8.6651e-06\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 196s 1s/step - loss: 8.2453e-06\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 195s 1s/step - loss: 5.2197e-06\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 195s 1s/step - loss: 3.3156e-06\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 195s 1s/step - loss: 4.2173e-06\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 195s 1s/step - loss: 3.2094e-05\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 195s 1s/step - loss: 4.0481e-06\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 199s 1s/step - loss: 3.2920e-06\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 199s 1s/step - loss: 1.7427e-06\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 198s 1s/step - loss: 3.1314e-06\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 199s 1s/step - loss: 1.5471e-06\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 198s 1s/step - loss: 1.4551e-06\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 192s 1s/step - loss: 1.4096e-06\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 190s 1s/step - loss: 1.3101e-06\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 190s 1s/step - loss: 1.2268e-06\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 190s 1s/step - loss: 1.2371e-06\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 190s 1s/step - loss: 1.1295e-06\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 190s 1s/step - loss: 0.0052\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 190s 1s/step - loss: 4.4955e-04\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 189s 1s/step - loss: 1.3841e-04\n",
      "Epoch 57/100\n",
      "177/177 [==============================] - 190s 1s/step - loss: 1.4150e-05\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 190s 1s/step - loss: 2.4837e-04\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 190s 1s/step - loss: 9.7092e-05\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 190s 1s/step - loss: 5.2896e-06\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 190s 1s/step - loss: 3.8172e-06\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 190s 1s/step - loss: 2.6361e-06\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 190s 1s/step - loss: 4.7408e-06\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 190s 1s/step - loss: 2.3960e-06\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 189s 1s/step - loss: 1.9878e-06\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 190s 1s/step - loss: 1.8534e-06\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 190s 1s/step - loss: 1.6338e-06\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 189s 1s/step - loss: 1.6577e-06\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 189s 1s/step - loss: 1.4696e-06\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 189s 1s/step - loss: 1.5462e-06\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 189s 1s/step - loss: 1.8393e-06\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 190s 1s/step - loss: 2.8112e-06\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 189s 1s/step - loss: 1.0715e-06\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 189s 1s/step - loss: 1.3566e-06\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 189s 1s/step - loss: 1.2169e-06\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 190s 1s/step - loss: 9.0122e-07\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 190s 1s/step - loss: 7.7527e-07\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 189s 1s/step - loss: 7.0400e-07\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 190s 1s/step - loss: 6.3448e-07\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 191s 1s/step - loss: 6.8252e-07\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 191s 1s/step - loss: 6.4861e-07\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 191s 1s/step - loss: 5.0604e-07\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 191s 1s/step - loss: 5.1852e-07\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 191s 1s/step - loss: 4.3636e-07\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 190s 1s/step - loss: 5.6345e-07\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 191s 1s/step - loss: 3.9451e-07\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 191s 1s/step - loss: 3.9868e-07\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 191s 1s/step - loss: 5.2755e-07\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 190s 1s/step - loss: 3.0244e-07\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 191s 1s/step - loss: 3.4433e-07\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 191s 1s/step - loss: 5.8685e-07\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 192s 1s/step - loss: 2.8581e-07\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 191s 1s/step - loss: 3.1747e-07\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 191s 1s/step - loss: 4.4829e-07\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 191s 1s/step - loss: 1.9639e-07\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 191s 1s/step - loss: 1.8726e-07\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 191s 1s/step - loss: 1.7133e-07\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 191s 1s/step - loss: 1.5834e-07\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 191s 1s/step - loss: 1.6806e-07\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 191s 1s/step - loss: 1.4089e-07\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor=\"loss\", min_delta=0, patience=20)\n",
    "\n",
    "history = model.fit(gen, epochs=epochs, verbose=1, callbacks=[es])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-15T07:47:03.267162Z",
     "iopub.status.busy": "2020-06-15T07:47:03.267162Z",
     "iopub.status.idle": "2020-06-15T07:47:03.346187Z",
     "shell.execute_reply": "2020-06-15T07:47:03.346187Z",
     "shell.execute_reply.started": "2020-06-15T07:47:03.267162Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name='joint_[64,64]_[linear,relu]_[10,10]'\n",
    "model.save(f'./cps/{model_name}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-15T07:47:04.658898Z",
     "iopub.status.busy": "2020-06-15T07:47:04.657897Z",
     "iopub.status.idle": "2020-06-15T07:47:04.787761Z",
     "shell.execute_reply": "2020-06-15T07:47:04.787761Z",
     "shell.execute_reply.started": "2020-06-15T07:47:04.658898Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAEYCAYAAACju6QJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de5xcdX3/8dd7LptsAgmXLAGSYAIEJFgRDCj+1PIQRVArtgVBq4JVoY+KWi+/Cvx+RaDUQuuvmFb0UQSEKhaE0pLWWKrQFhsxspGb4ZYLQTbBsLkCue1lPr8/5uxmmOwmM7uzc84s7+fjsY+dc+Z7Zr5zcrLv+X7P95yvIgIzMzNrLbm0K2BmZmb1c4CbmZm1IAe4mZlZC3KAm5mZtSAHuJmZWQsqpF2BsTJt2rSYPXt22tUwMzMblaVLl66PiI7q9eM2wGfPnk1nZ2fa1TAzMxsVSc8Otd5d6GZmZi2oqQEu6XRJT0laIeniIZ5/u6RfSuqTdFbVc+dJWp78nNe8WpuZmWVP0wJcUh64DjgDmAd8SNK8qmK/Bs4Hvl+17QHAV4A3AScBX5G0/1jX2czMLKua2QI/CVgREasioge4DTizskBErI6IR4FS1bbvBn4cERsjYhPwY+D0ZlTazMwsi5oZ4DOA5yqWu5J1DdtW0gWSOiV1dnd3j7iiZmZmWdfMANcQ62qdSaWmbSPi+oiYHxHzOzp2G3FvZmY2bjTzMrIuYFbF8kxgbR3bnlK17X81pFZmZlazUqnE+vXr2bx5M/39/WlXp+VNnDiRmTNnUiwW6962mQH+IDBX0hxgDXAu8OEat70H+GrFwLXTgEsaX0UzM9uTrq4uJDF79myKxSLSUB2kVouIYMOGDXR1dTFnzpy6t29aF3pE9AEXUQ7jJ4AfRMQySVdKej+ApBMldQFnA38vaVmy7Ubgzyl/CXgQuDJZ1xR/+aMn+NhNv2jW25mZZdbWrVuZMWMGbW1tDu9RksSBBx7Ijh07RrR9U+/EFhGLgEVV6y6rePwg5e7xoba9CbhpTCs4jO6XdrKq++U03trMLHNyOd8DrFFG8yXI/wo1KOREX3+t4+3MzMzGngO8BoV8jr5S9aXpZmZm6XGA16CYE30lt8DNzGyXm2++mUIhvTnBHOA1KORz7kI3MxsH3vnOd3L++ec35LXOOecc1qxZ05DXGolxO51oIxXyorffXehmZq8GPT09tLW17bVce3s77e3tTajR0NwCr0Exl3MXuplZizv//PO59957ueWWW5CEJG6++WYkceutt/Ke97yHyZMnc+mllxIRfOpTn+KII46gvb2dww8/nEsvvZSdO3cOvl51F/rA8uLFiznhhBOYNGkSJ554IkuXLh2Tz+MWeA0KedFfCiLC1z2amVW54l+X8fjaF5v+vvMOncJXfufYmssvWLCAVatWccghh7BgwQIAXnyxXO8vf/nLXH311XzjG99AEhHB9OnT+f73v8/06dN59NFHufDCCykWi1xxxRXDvkepVOKSSy5hwYIFdHR08NnPfpYPfvCDPPXUUw0/X+4Ar0ExX+6o6O0P2goOcDOzVjR16lTa2tpob2/n4IMPBhi8icqFF17IRz7ykVeUv+qqqwYfz549m5UrV/LNb35zjwEeEXz961/nhBNOAODKK6/k5JNPZuXKlRx99NEN/TwO8BoUcuXQ7iuVaPNZBzOzV6inFZxVJ5100m7rvv3tb3PDDTewevVqtm7dSl9fH6W9XFIsieOOO25wecaM8sSZ69ata3iAO41qUKhogZuZ2fgzefLkVyzfcccdfPrTn+acc85h0aJFPPTQQ1x22WX09vbu8XVyuRz5fH5weeC0696CfyTcAq9BMZ+0wD0S3cyspbW1tdU0i9r999/P8ccfzxe+8IXBdatXrx7DmtXPLfAaFJL7/nokuplZa5szZw5Lly5l5cqVrF+/ftgW9dFHH81jjz3G3XffzcqVK1mwYAF33XVXk2u7Zw7wGhSSFrivBTcza21f/OIXmTZtGscddxwdHR0sXrx4yHIXXnghH/3oR/n4xz/O8ccfz5IlS7j88subW9m9UMT4bFXOnz8/Ojs7G/Ja//xQF5+//RH+60unMHva5L1vYGY2Tj3xxBMcc8wxaVdjXNnbPpW0NCLmV693C7wGu7rQ3QI3M7NscIDXoDjYhT4+eyvMzKz1OMBrMNgCd4CbmVlGOMBrMDiIzV3oZmaWEQ7wGrgFbma2y3gd/JyG0exLB3gNCr6Ri5kZAMVike3bt6ddjXGjt7d3xJOcOMBrMDiIzTdyMbNXuYMOOog1a9awbds2t8RHqVQqsW7dOqZOnTqi7X0r1Rrs6kJ3C9zMXt2mTJkCwNq1a/d6X3Dbu8mTJzNt2rQRbesAr8FgF7pb4GZmTJkyZTDILT3uQq/BwHzgHsRmZmZZ4QCvQeV84GZmZlngAK9B0fOBm5lZxjjAa+DLyMzMLGsc4DUYGIXuy8jMzCwrHOA1KLoFbmZmGeMAr0HBo9DNzCxjHOA1GBiF7slMzMwsKxzgNfB14GZmljUO8Brkc0LyOXAzM8sOB3iNirmcR6GbmVlmNDXAJZ0u6SlJKyRdPMTzEyTdnjy/RNLsZH1R0i2SHpP0hKRLmllvKF8L7ha4mZllRdMCXFIeuA44A5gHfEjSvKpinwA2RcSRwLXANcn6s4EJEfFbwBuBCwfCvVnyOflObGZmlhnNbIGfBKyIiFUR0QPcBpxZVeZM4Jbk8Z3AqZIEBDBZUgFoB3qAF5tT7bJiPud7oZuZWWY0M8BnAM9VLHcl64YsExF9wBbgQMphvhV4Hvg18LWI2Fj9BpIukNQpqbO7u7uhlS/k5FHoZmaWGc0McA2xrjoRhytzEtAPHArMAb4o6fDdCkZcHxHzI2J+R0fHaOv7CsV8zl3oZmaWGc0M8C5gVsXyTGDtcGWS7vKpwEbgw8C/R0RvRLwALAbmj3mNKxTyche6mZllRjMD/EFgrqQ5ktqAc4GFVWUWAuclj88C7ouIoNxt/g6VTQbeDDzZpHoD7kI3M7NsaVqAJ+e0LwLuAZ4AfhARyyRdKen9SbEbgQMlrQC+AAxcanYdsA/wK8pfBL4TEY82q+7gQWxmZpYthWa+WUQsAhZVrbus4vEOypeMVW/38lDrm6l8Hbhb4GZmlg2+E1uNCr4Tm5mZZYgDvEZF34nNzMwyxAFeo0Iu5y50MzPLDAd4jQp5eT5wMzPLDAd4jYp5t8DNzCw7HOA1KuREr8+Bm5lZRjjAa1S+DtwtcDMzywYHeI08H7iZmWWJA7xGhZwnMzEzs+xwgNeo6MlMzMwsQxzgNcp7MhMzM8sQB3iNyvOBuwVuZmbZ4ACvUSEnj0I3M7PMcIDXqOAbuZiZWYY4wGtU9K1UzcwsQxzgNSrkckRAv7vRzcwsAxzgNSrkBeCBbGZmlgkO8BoVkwB3C9zMzLLAAV6jQq68qzyQzczMssABXqOBFrgHspmZWRY4wGtUyLsFbmZm2eEAr1Eh50FsZmaWHQ7wGhUHWuAexGZmZhngAK/RwGVknhPczMyywAFeo4FR6J4T3MzMssABXqOBUeieE9zMzLLAAV6jgVHoboGbmVkWOMBrNDAK3efAzcwsCxzgNRoMcI9CNzOzDHCA12hXF7pb4GZmlj4HeI0GB7H5HLiZmWWAA7xGg5OZeBS6mZllgAO8RoOTmbgFbmZmGeAAr9HgZCZugZuZWQY0NcAlnS7pKUkrJF08xPMTJN2ePL9E0uyK514v6QFJyyQ9JmliM+u+azITt8DNzCx9TQtwSXngOuAMYB7wIUnzqop9AtgUEUcC1wLXJNsWgO8BfxQRxwKnAL1NqjpQMZmJA9zMzDKgmS3wk4AVEbEqInqA24Azq8qcCdySPL4TOFWSgNOARyPiEYCI2BAR/U2qN1AxmYm70M3MLAOaGeAzgOcqlruSdUOWiYg+YAtwIHAUEJLukfRLSX861BtIukBSp6TO7u7uhla+mHML3MzMsqOZAa4h1lWn4XBlCsBbgT9Ifv+upFN3KxhxfUTMj4j5HR0do63vK7gFbmZmWdLMAO8CZlUszwTWDlcmOe89FdiYrP/viFgfEduARcAJY17jCgVfRmZmZhnSzAB/EJgraY6kNuBcYGFVmYXAecnjs4D7IiKAe4DXS5qUBPtvA483qd6Au9DNzCxbCs16o4jok3QR5TDOAzdFxDJJVwKdEbEQuBH4rqQVlFve5ybbbpL0N5S/BASwKCJ+2Ky6A+RyIid3oZuZWTY0LcABImIR5e7vynWXVTzeAZw9zLbfo3wpWWoK+Zy70M3MLBN8J7Y6FHPyfOBmZpYJDvA6FPI5zwduZmaZ4ACvQyEnzwduZmaZ4ACvQyEvj0I3M7NMcIDXoZDL0etR6GZmlgEO8DoU3QI3M7OMcIDXoTyIzS1wMzNLnwO8DuVBbG6Bm5lZ+kYV4JL2kfReSXMbVaEsK+Zzvg7czMwyoa4Al/R9SZ9NHheBJcC/AsskvW8M6pcphbx8HbiZmWVCvS3wU4DFyePfAfYFDgEuB/6sYbXKqGIu5+vAzcwsE+oN8AOAdcnjdwF3RcQ64PvAMY2sWBb5OnAzM8uKegO8G5iTPH4X8J/J40nAuG+aFvI5et2FbmZmGVDvbGR3ALdKehqYAvw4Wf8GYHkjK5ZFxZzo92VkZmaWAfUG+J8CXcBhwBcjYluy/lDg242sWBa5C93MzLKirgCPiD7gb4ZY/7WG1SjDyvOBuwVuZmbpq/cysuMkHVux/B5Jd0i6XFK9rfmWU8z5MjIzM8uGegex/T3wWwCSZgJ3AvsAnwKuamzVsqeQz7kL3czMMqHeAD8aeCh5/HvAgxFxBvAx4JxGViyLinnPB25mZtlQb4C3ATuSx6cAP0oePw0c3KA6ZVbeXehmZpYR9Qb4U8BZkg6jfB34T5L1hwCbGlmxLCr4TmxmZpYR9Qb4FcBXgWeA/4mIzmT9aezqWh+3PB+4mZllRb2Xkd2dtL4PAR6teOpe4K5GViyLPB+4mZllRd2XfiX3Pl8naaIkImJHRDwwBnXLnGIyH3hEICnt6piZ2atY3fOBS/q4pBXAy8DLkpZLOr/hNcugQr68u/o9kM3MzFJWVwtc0ueAq4FvAf8NCPht4JuS9o2Iv2t8FbOjkC+3uvtKQSGfcmXMzOxVrd4u9M8An4uI6yvW/YukJ4H/DYzrAC/myi3w3v4SE4tOcDMzS0+9XeizKA9Yq3Zv8ty4NtgC90h0MzNLWb0B3kX5Bi7VTkmeG9cGzoH3eiS6mZmlrN4u9G8BfyvpSOCnQFA+B/4Z4LIG1y1zijm3wM3MLBvqvQ78a5K2A19OfqDc8v5SRHyr0ZXLmoEWuAPczMzSNpLrwK8DrpO0b7L8UsNrlVHF5By4u9DNzCxtew1wSf+xl+cHH0fEaQ2oU2YVcr4O3MzMsqGWFviaMa9FixgYhe4JTczMLG17DfCI+Hij3kzS6cACIA/cEBFXVz0/AfgH4I3ABuCciFhd8fxhwOPA5RHxtUbVq1ZFX0ZmZmYZUfetVEdKUh64DjgDmAd8SNK8qmKfADZFxJHAtcA1Vc9fy645yJtuoAvdE5qYmVnamhbgwEnAiohYFRE9wG3AmVVlzgRuSR7fCZyq5CS7pA8Aq4BlTarvbnZ1obsFbmZm6WpmgM8AnqtY7krWDVkmIvqALcCBkiZTvmztij29gaQLJHVK6uzu7m5YxQcMtsAd4GZmlrJmBvhQ829WJ+FwZa4Aro2Il/f0BhFxfUTMj4j5HR0dI6zm8Aq+jMzMzDKi7uvAR6GLV94vfSawdpgyXZIKwFRgI/Am4CxJfwXsB5Qk7YiIb4x9tXcpugVuZmYZ0cwAfxCYK2kO5UvTzgU+XFVmIXAe8ABwFnBfRATwtoECki4HXm52eEPlZCZugZuZWbqaFuAR0SfpIuAeypeR3RQRyyRdCXRGxELgRuC7klZQbnmf26z61WLXndjcAjczs3Q1swVORCwCFlWtu6zi8Q7g7L28xuVjUrka7BrE5ha4mZmlq5mD2Fqe5wM3M7OscIDXoej5wM3MLCMc4HUoeD5wMzPLCAd4HQbmA/dkJmZmljYHeB0GJzPxKHQzM0uZA7wOHoVuZmZZ4QCvQ9GTmZiZWUY4wOsgiXxOnk7UzMxS5wCvUyEnnwM3M7PUOcDrVMznfBmZmZmlzgFep0JeHsRmZmapc4DXqZCTJzMxM7PUOcDrVMjl3AI3M7PUOcDrVO5CdwvczMzS5QCvUzGfcxe6mZmlzgFep0LOg9jMzCx9DvA6FfI534nNzMxS5wCvUzHvO7GZmVn6HOB1KnehuwVuZmbpcoDXqdyF7ha4mZmlywFep3IXulvgZmaWLgd4nXwjFzMzywIHeJ2KeXkUupmZpc4BXqdCLudR6GZmljoHeJ18K1UzM8sCB3idyrdSdQvczMzS5QCvk68DNzOzLHCA18m3UjUzsyxwgNepmBf97kI3M7OUOcDrlHcXupmZZYADvE4exGZmZlngAK+TB7GZmVkWOMDrVMjn6CsFEQ5xMzNLjwO8TsWcADyhiZmZpaqpAS7pdElPSVoh6eIhnp8g6fbk+SWSZifr3yVpqaTHkt/vaGa9KxXy5V3mbnQzM0tT0wJcUh64DjgDmAd8SNK8qmKfADZFxJHAtcA1yfr1wO9ExG8B5wHfbU6td1fMl1vgHshmZmZpamYL/CRgRUSsioge4DbgzKoyZwK3JI/vBE6VpIh4KCLWJuuXARMlTWhKrasUBrrQ3QI3M7MUNTPAZwDPVSx3JeuGLBMRfcAW4MCqMr8PPBQRO6vfQNIFkjoldXZ3dzes4pV2daG7BW5mZulpZoBriHXVzdg9lpF0LOVu9QuHeoOIuD4i5kfE/I6OjhFXdE92daG7BW5mZulpZoB3AbMqlmcCa4crI6kATAU2JsszgX8GPhYRK8e8tsMo5NwCNzOz9DUzwB8E5kqaI6kNOBdYWFVmIeVBagBnAfdFREjaD/ghcElELG5ajYdQGGiB+xy4mZmlqGkBnpzTvgi4B3gC+EFELJN0paT3J8VuBA6UtAL4AjBwqdlFwJHAn0l6OPk5qFl1r1QcOAfuUehmZpaiQjPfLCIWAYuq1l1W8XgHcPYQ210FXDXmFayBR6GbmVkW+E5sdRpogff6HLiZmaXIAV6ngXPgvpWqmZmlyQFep4FR6G6Bm5lZmhzgdRq4DtznwM3MLE0O8Drlk0Fs/e5CNzOzFDnA6+RBbGZmlgUO8Dp5EJuZmWWBA7xOHsRmZmZZ4ACvkwexmZlZFjjA61TwrVTNzCwDHOB1KuY8mYmZmaXPAV6nwRa4z4GbmVmKHOB18ih0MzPLAgd4nYqDo9Ad4GZmlh4HeJ0GW+DuQjczsxQ5wOs0MB94r7vQzcwsRQ7wOkmikJNb4GZmlioH+AgU8vIgNjMzS5UDfASKuZxvpWpmZqlygI9AIS/fStXMzFLlAB+BQj7nW6k20LaePl7a0Zt2NczMWooDfAQKOfk68Ab6/O0Pc95Nv0i7GmZmLaWQdgVaUbkL3S3wRujpK3H/0+vZ3ttP90s76dh3QtpVMjNrCW6Bj0Axl/Mo9AZ5pGsz23v7AfifFd0p18bMrHU4wEfAg9ga54GVG5Bg34kF7n96fdrVMTNrGe5CH4FCzoPYGuVnK9cz75ApHNGxDz9dvp5SKcgld7uz8enmxc+w78Qiv//GmWlXxayluQU+AsW8B7E1wo7efn757GbecsSBvP2oDta/vJMnfvNi2tWyMfTSjl7+8kdPctUPH2dnX3/a1TFraQ7wEfBlZI2x9NlN9PSXeMsR03jb3GkA/HS5u9HHs3uWrWNnX4lN23r5yeMvpF0ds5bmAB8BX0bWGA+s3EA+J06ccwDTp0zktQfvy/1PeyDbeHb3w2uYdUA7h06dyO2dz6VdHbOW5gAfgWI+58vIGuBnK9dz3Myp7DOhPBTjbXOn0bl6E9t6+lKumY2FF17aweIV6/nAG2Zw1vxZ/HR5N12btqVdLbOW5QAfAU9mMnov7+zjka4tnHzEgYPr3n5UBz39JZas2phizWys/Osjz1MKOPMNMzg7GcB259KulGtl1roc4CNQyOXchT5KDz6zkf5S8JYjpg2uO3H2AUwo5Lh/ubvRx6O7H17D62ZM4ciD9mHWAZN465HTuKOzi35/GTYbEQf4CBR9J7ZR+9nK9bTlc7zxNfsPrptYzPOmww/0efBxaFX3yzzatYUPvGHG4LoPzp/Fms3bWbzCAxfNRsIBPgLtxTxrN29n0WPPE+HWw0g8sGoDJ7xmPyYW869Y//a501jZvZU1m7enVDMbC3c/vBYJ3vf6QwfXnXbsdPabVPRgNrMRamqASzpd0lOSVki6eIjnJ0i6PXl+iaTZFc9dkqx/StK7m1nvan90yhHMOmASf3zrLznn+p+zbO2WNKtTt9Xrt/KDzudY8JPlfPnOR/nojUv43G0PsfTZjU35QrJ5Ww/L1r74iu7zAW8/qgOAn7oVPm5EBHc/vIaTDz+Qg6dOHFw/oZDnd4+fwY+XrWPT1p4Ua2jWmpp2JzZJeeA64F1AF/CgpIUR8XhFsU8AmyLiSEnnAtcA50iaB5wLHAscCvxE0lERkcqdII6avi8//OzbuO3BX/P//uNp3vd3/8Oprz2Io6bvy+xpk5kzbTKH7tfO1PYik9vySOnfWSwiWPLMRm746TPc++Q6BnJ62j4TOHS/iTzy3Gbufngtx82cyh++dQ5nvO4Q2gpj8/3u56s2EsErBrANmHvQPhw8ZSL/8MCzTCzmeXPVH31rPY90bWH1hm388SlH7vbcOSfO4juLV7Pg3uWc9caZHHnQPrv1ypjZ0NSsLmBJJwOXR8S7k+VLACLiLyvK3JOUeUBSAfgN0AFcXFm2stxw7zd//vzo7Owcq48zaMv2Xr5x33J+8sQLPLdx226j0ws5MaW9yOQJeYq5HPmcKORztOXFhEKetkKOCYUchbzIqfwjMfhbgJLHeYl8TuRyStaX30PsXjanXWUk8cDKDTy2Zgv7Tyry0Te/hjOPn8HM/duZUCj/sdy6s4+7ftnFd362mlXdWynkxPQpEzlk6kQO3a+dKe0F+ktQKgWlCCRoK+Qo5nO0FXLkk8oMfPrevhLbe/vZ3tPP9t5+evuDfA7yObHyha38euM2HvnKaUN+Sbh1ybNc/aMneWlH+XKyOdMmc9T0fZjUVmBiMU97MU+xMLC/Xvn5yztEyX5JPj8j+wK1t+9dlU+XAvpLJfojBo+BwX+vin/XobYd6r0qv/RFBKWAvlLQXyrRVwqEKOTKr19Ijolmquc76QMrN7DkmY10/t93MmVicbfnz//OL/ivp8o9LjnBYQdMYsb+5S/AU9vbmNpeZHtPH89t2k7Xpm10bdpOKYIDJrVxwD5tHDB5wuCX5ckTCkxuy+92XGXhS/RYGucfr+W8fsZ+vHXu7j2MIyVpaUTM3219EwP8LOD0iPhksvxR4E0RcVFFmV8lZbqS5ZXAm4DLgZ9HxPeS9TcCP4qIO6ve4wLgAoDDDjvsjc8+++yYf65Kvf0l1mzazjMbtrJuyw62bO9ly/ZeXtzRy7ad/fSWgr7+Er39QW9/iZ6+Ejv7+unpL9HbFwTlP9SlCEqlIIAIyutL5fX9pXKZgX+3gX+9UkS5bPK7FK/c/rADJnH+W+bweyfM2GMLp1QK7l/ezYOrN/L85h2s2byd57fs4OWdfeSkcghLlILBz9DTX6K/FK/4QpHPiUltedrbyoFbyOcolYL+5LO9c950Ln3PMcPWo78UPPH8i/x81QZ+vmoDv964jR295S8FO3r62dlfgoF9lXxWks+bpsowHfi8jaxTPqfBL0v9yfHQCj44fyZ/ddZxQz7X11/imfVbeXrdyzy97iWWv/AS617cyeZtPWzZ3seL23uZUMwxa/9JzNy/nZn7T6KQFxte7mHj1p1s3NrDizv62Loz+enxLVotXee/ZTaXv//Yhr3ecAHezMlMhvqOWP3XZ7gytWxLRFwPXA/lFni9FRytYj7H7GmTmT1tcrPfumFyOXHK0QdxytEHpVqPfE68bsZUXjdjKp982+Ejeo2oCM/hDqJht63htSspaW0PZeDL2HDbVr/XUIGfU3mfVLckI2nx7+lLQhB77IWIvX7avddvbybs4XRMIZ9j7vR9mTt9X97LIfW/eJWBL04Dquvb6P0x1iL23MJO+0ur7W64vwWN1swA7wJmVSzPBNYOU6Yr6UKfCmyscVuzV1BVt3WDX73mkrt3bzeuUpIo5t1/WimXE7kG7mOzrGrmKPQHgbmS5khqozwobWFVmYXAecnjs4D7otxcWQicm4xSnwPMBX7RpHqbmZllTtNa4BHRJ+ki4B4gD9wUEcskXQl0RsRC4Ebgu5JWUG55n5tsu0zSD4DHgT7g02mNQDczM8uCpg1ia7ZmjUI3MzMbS8MNYvOd2MzMzFqQA9zMzKwFOcDNzMxakAPczMysBTnAzczMWtC4HYUuqRto5L1UpwGeuHjkvP9Gx/tvdLz/Rsf7b3RGu/9eExEd1SvHbYA3mqTOoYbxW228/0bH+290vP9Gx/tvdMZq/7kL3czMrAU5wM3MzFqQA7x216ddgRbn/Tc63n+j4/03Ot5/ozMm+8/nwM3MzFqQW+BmZmYtyAFuZmbWghzgNZB0uqSnJK2QdHHa9ckySbMk/aekJyQtk/S5ZP0Bkn4saXnye/+065plkvKSHpL0b8nyHElLkv13u6S2tOuYVZL2k3SnpCeT4/BkH3+1k/T55P/uryT9o6SJPv6GJ+kmSS9I+lXFuiGPN5X9bZIlj0o6YTTv7QDfC0l54DrgDGAe8CFJ89KtVab1AV+MiGOANwOfTvbXxcC9ETEXuDdZtuF9DniiYvka4Npk/20CPpFKrVrDAuDfI+K1wHGU96OPvxpImgF8FpgfEa8D8sC5+Pjbk5uB06vWDXe8nQHMTX4uAL41mjd2gO/dScCKiFgVET3AbcCZKdcpsyLi+Yj4ZfL4Jcp/PGdQ3me3JMVuAT6QTg2zT9JM4L3ADcmygHcAdyZFvP+GIWkK8HbgRoCI6ImIzfj4q0cBaJdUACYBz+Pjb4WUJLwAAAThSURBVFgRcT+wsWr1cMfbmcA/RNnPgf0kHTLS93aA790M4LmK5a5kne2FpNnA8cASYHpEPA/lkAcOSq9mmfd14E+BUrJ8ILA5IvqSZR+Dwzsc6Aa+k5yCuEHSZHz81SQi1gBfA35NObi3AEvx8Vev4Y63huaJA3zvNMQ6X3u3F5L2Af4J+JOIeDHt+rQKSe8DXoiIpZWrhyjqY3BoBeAE4FsRcTywFXeX1yw5V3smMAc4FJhMudu3mo+/kWno/2UH+N51AbMqlmcCa1OqS0uQVKQc3rdGxF3J6nUDXUXJ7xfSql/G/S/g/ZJWUz5d8w7KLfL9ki5N8DG4J11AV0QsSZbvpBzoPv5q807gmYjojohe4C7gLfj4q9dwx1tD88QBvncPAnOTUZhtlAd0LEy5TpmVnK+9EXgiIv6m4qmFwHnJ4/OAu5tdt1YQEZdExMyImE35WLsvIv4A+E/grKSY998wIuI3wHOSjk5WnQo8jo+/Wv0aeLOkScn/5YH95+OvPsMdbwuBjyWj0d8MbBnoah8J34mtBpLeQ7kVlAduioi/SLlKmSXprcBPgcfYdQ73UsrnwX8AHEb5j8TZEVE98MMqSDoF+FJEvE/S4ZRb5AcADwEfiYidadYvqyS9gfIAwDZgFfBxyo0VH381kHQFcA7lK0oeAj5J+Tytj78hSPpH4BTKU4auA74C/AtDHG/Jl6JvUB61vg34eER0jvi9HeBmZmatx13oZmZmLcgBbmZm1oIc4GZmZi3IAW5mZtaCHOBmZmYtyAFuZk0l6RRJkdzz3cxGyAFuZmbWghzgZmZmLcgBbvYqI+kzkp6UtEPSckn/Z+A+15JWS/qLZBavFyWtl3SNpFzF9vtK+ntJ3clrdEo6reo9DpL0HUnrkjJPSfrDqqocI+l+SdskPS7p3U34+GbjhgPc7FVE0uXAl4BLgGOAzwEXUr7944DPUJ5g4UTg88BFwJ9UPH8T8G7gI5Sni10M/Juk1ybv0Q78N3Ac8AfAvOQ1t1VV52vAV5NyncDtkvZrzCc1G/98K1WzVwlJk4D1wO9FxL9XrP8Y8LcRsV8yC9pzEfG2iue/CnwsImZKOhJYDrw3IhZVlPkl8HBE/KGkTwDXAUdGRNcQ9TiF8uQYvz8wW52kgynPP316RNzT6M9uNh4V9l7EzMaJY4F24J8kVX5zzwMTJXUkyw9UbbcYuETSFMqtaYD7q8rcD5ycPH4j8PhQ4V3l4YEHEfEbSf3A9Jo+iZk5wM1eRQZOmZ0NPD3E88PNzqUaXltA5ZeCWrr2eoZY59N6ZjXyfxazV49lwA7g8IhYMcRPf1LuzVXbnQysjYgXk9cAeHtVmbdVPLcUONbXeZuNLQe42atERLxMedDYVyVdJOloScdKOlfSNRVF3yDpcklHSfow5YFu1yavsRK4A/impHdLeq2kBcDrgL9Otv9H4FlgoaR3Spoj6VRJ5zTrs5q9GrgL3exVJCL+XNJayqPCvwZsp9ydfnNFsb8DXkN5ZHgf8C2SAE98knJYfw+YAjwGvC8inkzeY5uk3wb+CrgN2AdYDVw9Vp/L7NXIo9DNbFAyCv2GiLgq7bqY2Z65C93MzKwFOcDNzMxakLvQzczMWpBb4GZmZi3IAW5mZtaCHOBmZmYtyAFuZmbWghzgZmZmLej/A6XBXYLXcxNbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 504x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zk0ao0QBel-I"
   },
   "source": [
    "## Extracting Embeddings\n",
    "\n",
    "Since we've already trained the weights of our base model - HinSAGE in this example - we can simply use `base_model.in_out_tensors` to obtain the trained node embedding model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2020-06-15T07:47:07.124379Z",
     "iopub.status.busy": "2020-06-15T07:47:07.124379Z",
     "iopub.status.idle": "2020-06-15T07:47:07.347053Z",
     "shell.execute_reply": "2020-06-15T07:47:07.347053Z",
     "shell.execute_reply.started": "2020-06-15T07:47:07.124379Z"
    },
    "id": "J2vdCBvnel-I"
   },
   "outputs": [],
   "source": [
    "x_emb_in, x_emb_out = hinsage_model.in_out_tensors()\n",
    "\n",
    "# for full batch models, squeeze out the batch dim (which is 1)\n",
    "# x_out = tf.squeeze(x_emb_out, axis=0)\n",
    "# emb_model = Model(inputs=x_emb_in, outputs=x_out)\n",
    "\n",
    "# not using full batch models\n",
    "emb_model = Model(inputs=x_emb_in, outputs=x_emb_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZfOk_QsBel-M"
   },
   "source": [
    "## Visualisation with TSNE\n",
    "\n",
    "Here we visualize the node embeddings with TSNE. As you can see below, the Deep Graph Infomax model produces well separated embeddings using unsupervised training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2020-06-15T07:47:09.179455Z",
     "iopub.status.busy": "2020-06-15T07:47:09.178455Z"
    },
    "id": "9uuztWSgel-M"
   },
   "outputs": [],
   "source": [
    "all_embeddings = emb_model.predict(hinsage_generator.flow(G.nodes()))\n",
    "\n",
    "# y = node_subjects.astype(\"category\")\n",
    "trans = TSNE(n_components=2)\n",
    "emb_transformed = pd.DataFrame(trans.fit_transform(all_embeddings), index=G.nodes())\n",
    "# emb_transformed[\"label\"] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf2gene = df[df['type'] == 'TSS']\n",
    "tfs = set(tf2gene['source'])\n",
    "print(tfs)\n",
    "\n",
    "def geneType(name):\n",
    "    if name in tfs:\n",
    "        return 1   # 1 represents TFs\n",
    "    else:\n",
    "        return 0   # 2 represents normal gene\n",
    "\n",
    "emb_transformed['type'] = emb_transformed.index.map(geneType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gVWq4nxel-O",
    "outputId": "8492234e-cae9-4d6e-ad4a-7221bf5b0676"
   },
   "outputs": [],
   "source": [
    "alpha = 0.7\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.scatter(\n",
    "    emb_transformed[0],\n",
    "    emb_transformed[1],\n",
    "    c=emb_transformed[\"type\"],\n",
    "    cmap=\"jet\",\n",
    "    alpha=alpha,\n",
    "    s=5\n",
    ")\n",
    "ax.set(aspect=\"equal\", xlabel=\"$X_1$\", ylabel=\"$X_2$\")\n",
    "plt.title(f\"TSNE visualization of HinSAGE embeddings for {model_name}\")\n",
    "\n",
    "plt.savefig(f'./img/{model_name}.png', dpi=150)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "colab": {
   "name": "deep-graph-infomax-embeddings.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
